2024-02-23 11:37:06,161 INFO    StreamThr :33212 [internal.py:wandb_internal():86] W&B internal server running at pid: 33212, started at: 2024-02-23 11:37:06.160942
2024-02-23 11:37:06,162 DEBUG   HandlerThread:33212 [handler.py:handle_request():146] handle_request: status
2024-02-23 11:37:06,168 INFO    WriterThread:33212 [datastore.py:open_for_write():87] open: D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\run-68mhhblq.wandb
2024-02-23 11:37:06,169 DEBUG   SenderThread:33212 [sender.py:send():382] send: header
2024-02-23 11:37:06,224 DEBUG   SenderThread:33212 [sender.py:send():382] send: run
2024-02-23 11:37:07,762 INFO    SenderThread:33212 [dir_watcher.py:__init__():211] watching files in: D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\files
2024-02-23 11:37:07,774 INFO    SenderThread:33212 [sender.py:_start_run_threads():1136] run started: 68mhhblq with start time 1708659426.160942
2024-02-23 11:37:07,770 DEBUG   HandlerThread:33212 [handler.py:handle_request():146] handle_request: check_version
2024-02-23 11:37:07,774 DEBUG   SenderThread:33212 [sender.py:send_request():409] send_request: check_version
2024-02-23 11:37:08,216 DEBUG   HandlerThread:33212 [handler.py:handle_request():146] handle_request: run_start
2024-02-23 11:37:08,246 DEBUG   HandlerThread:33212 [system_info.py:__init__():27] System info init
2024-02-23 11:37:08,246 DEBUG   HandlerThread:33212 [system_info.py:__init__():42] System info init done
2024-02-23 11:37:08,246 INFO    HandlerThread:33212 [system_monitor.py:start():194] Starting system monitor
2024-02-23 11:37:08,247 INFO    SystemMonitor:33212 [system_monitor.py:_start():158] Starting system asset monitoring threads
2024-02-23 11:37:08,247 INFO    HandlerThread:33212 [system_monitor.py:probe():214] Collecting system info
2024-02-23 11:37:08,255 INFO    SystemMonitor:33212 [interfaces.py:start():190] Started cpu monitoring
2024-02-23 11:37:08,255 INFO    SystemMonitor:33212 [interfaces.py:start():190] Started disk monitoring
2024-02-23 11:37:08,256 INFO    SystemMonitor:33212 [interfaces.py:start():190] Started gpu monitoring
2024-02-23 11:37:08,269 INFO    SystemMonitor:33212 [interfaces.py:start():190] Started memory monitoring
2024-02-23 11:37:08,287 INFO    SystemMonitor:33212 [interfaces.py:start():190] Started network monitoring
2024-02-23 11:37:08,293 DEBUG   HandlerThread:33212 [system_info.py:probe():151] Probing system
2024-02-23 11:37:08,294 DEBUG   HandlerThread:33212 [system_info.py:_probe_git():136] Probing git
2024-02-23 11:37:08,427 DEBUG   HandlerThread:33212 [system_info.py:_probe_git():144] Probing git done
2024-02-23 11:37:08,427 DEBUG   HandlerThread:33212 [system_info.py:probe():199] Probing system done
2024-02-23 11:37:08,427 DEBUG   HandlerThread:33212 [system_monitor.py:probe():223] {'os': 'Windows-10-10.0.22621-SP0', 'python': '3.9.18', 'heartbeatAt': '2024-02-23T03:37:08.293725', 'startedAt': '2024-02-23T03:37:06.138881', 'docker': None, 'cuda': None, 'args': ('--cfg', 'config/temp-train.yaml', '--dataset', 'imagenet', '--data_path', '/data1/hzh/imagenet', '--batch_size', '4', '--output', 'output'), 'state': 'running', 'program': 'D:\\WorkSpace\\python\\spike-driven-transformer\\test.py', 'codePathLocal': 'test.py', 'codePath': 'test.py', 'git': {'remote': 'https://github.com/hanzh0816/spike-driven-transformer.git', 'commit': '7a269ee91b0d95b612a465facd002d138ec9a90b'}, 'email': '15091693112@163.com', 'root': 'D:/WorkSpace/python/spike-driven-transformer', 'host': 'LAPTOP-HZH', 'username': 'lenovo2', 'executable': 'D:\\APP\\Work\\Anaconda\\envs\\pytorch\\python.exe', 'cpu_count': 14, 'cpu_count_logical': 20, 'cpu_freq': {'current': 2400.0, 'min': 0.0, 'max': 2400.0}, 'cpu_freq_per_core': [{'current': 2400.0, 'min': 0.0, 'max': 2400.0}], 'disk': {'/': {'total': 931.4960899353027, 'used': 590.4815254211426}}, 'gpu': 'NVIDIA GeForce RTX 3050 4GB Laptop GPU', 'gpu_count': 1, 'gpu_devices': [{'name': 'NVIDIA GeForce RTX 3050 4GB Laptop GPU', 'memory_total': 4294967296}], 'memory': {'total': 15.731315612792969}}
2024-02-23 11:37:08,427 INFO    HandlerThread:33212 [system_monitor.py:probe():224] Finished collecting system info
2024-02-23 11:37:08,427 INFO    HandlerThread:33212 [system_monitor.py:probe():227] Publishing system info
2024-02-23 11:37:08,427 DEBUG   HandlerThread:33212 [system_info.py:_save_conda():208] Saving list of conda packages installed into the current environment
2024-02-23 11:37:08,770 INFO    Thread-16 :33212 [dir_watcher.py:_on_file_created():271] file/dir created: D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\files\conda-environment.yaml
2024-02-23 11:37:11,075 DEBUG   HandlerThread:33212 [system_info.py:_save_conda():220] Saving conda packages done
2024-02-23 11:37:11,076 INFO    HandlerThread:33212 [system_monitor.py:probe():229] Finished publishing system info
2024-02-23 11:37:11,222 INFO    SenderThread:33212 [sender.py:finish():1572] shutting down sender
2024-02-23 11:37:11,222 INFO    SenderThread:33212 [dir_watcher.py:finish():358] shutting down directory watcher
2024-02-23 11:37:11,798 INFO    SenderThread:33212 [dir_watcher.py:_on_file_modified():288] file/dir modified: D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\files\conda-environment.yaml
2024-02-23 11:37:11,798 INFO    SenderThread:33212 [dir_watcher.py:_on_file_created():271] file/dir created: D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\files\wandb-metadata.json
2024-02-23 11:37:11,799 INFO    SenderThread:33212 [dir_watcher.py:finish():388] scan: D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\files
2024-02-23 11:37:11,799 INFO    SenderThread:33212 [dir_watcher.py:finish():402] scan save: D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\files\conda-environment.yaml conda-environment.yaml
2024-02-23 11:37:11,799 INFO    SenderThread:33212 [dir_watcher.py:finish():402] scan save: D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\files\config.yaml config.yaml
2024-02-23 11:37:11,801 INFO    SenderThread:33212 [dir_watcher.py:finish():402] scan save: D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\files\wandb-metadata.json wandb-metadata.json
2024-02-23 11:37:11,802 INFO    SenderThread:33212 [file_pusher.py:finish():172] shutting down file pusher
2024-02-23 11:37:11,802 INFO    SenderThread:33212 [file_pusher.py:join():178] waiting for file pusher
2024-02-23 11:37:11,812 INFO    WriterThread:33212 [datastore.py:close():296] close: D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\run-68mhhblq.wandb
2024-02-23 11:37:13,437 INFO    wandb-upload_0:33212 [upload_job.py:push():131] Uploaded file D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\files\conda-environment.yaml
2024-02-23 11:37:13,617 INFO    wandb-upload_2:33212 [upload_job.py:push():131] Uploaded file D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\files\wandb-metadata.json
2024-02-23 11:37:13,796 INFO    wandb-upload_1:33212 [upload_job.py:push():131] Uploaded file D:\WorkSpace\python\spike-driven-transformer\wandb\run-20240223_113706-68mhhblq\files\config.yaml
2024-02-23 11:37:14,362 INFO    SenderThread:33212 [file_stream.py:finish():595] file stream finish called
2024-02-23 11:37:17,633 INFO    SenderThread:33212 [file_stream.py:finish():599] file stream finish is done
2024-02-23 11:37:19,654 ERROR   StreamThr :33212 [internal.py:wandb_internal():174] Thread HandlerThread:
Traceback (most recent call last):
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\sdk\internal\internal_util.py", line 49, in run
    self._run()
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\sdk\internal\internal_util.py", line 100, in _run
    self._process(record)
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\sdk\internal\internal.py", line 279, in _process
    self._hm.handle(record)
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\sdk\internal\handler.py", line 138, in handle
    handler(record)
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\sdk\internal\handler.py", line 148, in handle_request
    handler(record)
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\sdk\internal\handler.py", line 688, in handle_request_run_start
    self._tb_watcher = tb_watcher.TBWatcher(
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\sdk\internal\tb_watcher.py", line 126, in __init__
    wandb.tensorboard.reset_state()
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\sdk\lib\lazyloader.py", line 58, in __getattr__
    module = self._load()
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\sdk\lib\lazyloader.py", line 33, in _load
    module = importlib.import_module(self.__name__)
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\importlib\__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\integration\tensorboard\__init__.py", line 3, in <module>
    from .log import _log, log, reset_state, tf_summary_to_dict  # noqa: F401
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\integration\tensorboard\log.py", line 35, in <module>
    Summary = pb.Summary if pb else None
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\util.py", line 209, in __getattribute__
    state.load()
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\wandb\util.py", line 202, in load
    self.module.__spec__.loader.exec_module(self.module)
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\tensorboard\compat\proto\summary_pb2.py", line 16, in <module>
    from tensorboard.compat.proto import tensor_pb2 as tensorboard_dot_compat_dot_proto_dot_tensor__pb2
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\tensorboard\compat\proto\tensor_pb2.py", line 16, in <module>
    from tensorboard.compat.proto import resource_handle_pb2 as tensorboard_dot_compat_dot_proto_dot_resource__handle__pb2
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\tensorboard\compat\proto\resource_handle_pb2.py", line 16, in <module>
    from tensorboard.compat.proto import tensor_shape_pb2 as tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\tensorboard\compat\proto\tensor_shape_pb2.py", line 36, in <module>
    _descriptor.FieldDescriptor(
  File "D:\APP\Work\Anaconda\envs\pytorch\lib\site-packages\google\protobuf\descriptor.py", line 553, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates
